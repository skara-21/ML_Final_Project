{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuwPZtYUU0Wc",
        "outputId": "2a7dce8f-161e-4120-b585-b5328e919aab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "FOLDERNAME='ML_final_project'\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from scripts.data_processor import DataPreprocessor"
      ],
      "metadata": {
        "id": "oZQIJX-b36s7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wmae_score(y_true, y_pred, weights):\n",
        "    return np.sum(weights * np.abs(y_true - y_pred)) / np.sum(weights)"
      ],
      "metadata": {
        "id": "o4wo5dWZuPb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FOLDERNAME='/content/drive/MyDrive/ML_final_project'\n",
        "DATAPATH=f'{FOLDERNAME}/data/'\n",
        "\n",
        "train_df=pd.read_csv(DATAPATH+'train.csv')\n",
        "test_df=pd.read_csv(DATAPATH+'test.csv')\n",
        "features_df=pd.read_csv(DATAPATH+'features.csv')\n",
        "stores_df=pd.read_csv(DATAPATH+'stores.csv')\n",
        "\n",
        "print(f\"Data loaded:\")\n",
        "print(f\"Train: {train_df.shape}\")\n",
        "print(f\"Test: {test_df.shape}\")\n",
        "print(f\"Features: {features_df.shape}\")\n",
        "print(f\"Stores: {stores_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxocGDZAt18t",
        "outputId": "c60325dc-05c1-4ffa-b621-f986c69004f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded:\n",
            "Train: (421570, 5)\n",
            "Test: (115064, 4)\n",
            "Features: (8190, 12)\n",
            "Stores: (45, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_df['Date']=pd.to_datetime(features_df['Date'])\n",
        "train_df['Date']=pd.to_datetime(train_df['Date'])\n",
        "test_df['Date']=pd.to_datetime(test_df['Date'])\n",
        "\n",
        "initial_rows=len(train_df)\n",
        "train_df=train_df[train_df['Weekly_Sales']>=0].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "s4mfpkRZuGNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def time_series_split_walmart(train_data, n_splits=5):\n",
        "    train_data=train_data.sort_values('Date')\n",
        "    dates=train_data['Date'].unique()\n",
        "    dates=np.sort(dates)\n",
        "\n",
        "    split_size=len(dates)//(n_splits+1)\n",
        "    splits=[]\n",
        "\n",
        "    for i in range(n_splits):\n",
        "        train_end_idx=(i+1) * split_size\n",
        "        val_start_idx=train_end_idx\n",
        "        val_end_idx=train_end_idx+split_size\n",
        "\n",
        "        train_dates=dates[:train_end_idx]\n",
        "        val_dates=dates[val_start_idx:val_end_idx]\n",
        "\n",
        "        train_idx=train_data[train_data['Date'].isin(train_dates)].index\n",
        "        val_idx=train_data[train_data['Date'].isin(val_dates)].index\n",
        "\n",
        "        splits.append((train_idx, val_idx))\n",
        "\n",
        "    return splits"
      ],
      "metadata": {
        "id": "cneh4z3huLps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_cross_validation(train_data):\n",
        "\n",
        "    lgb_params={\n",
        "        'objective': 'regression',\n",
        "        'metric': 'mae',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': 63,\n",
        "        'learning_rate': 0.03,\n",
        "        'feature_fraction': 0.8,\n",
        "        'bagging_fraction': 0.8,\n",
        "        'bagging_freq': 5,\n",
        "        'max_depth': 8,\n",
        "        'min_child_samples': 20,\n",
        "        'reg_alpha': 0.1,\n",
        "        'reg_lambda': 0.1,\n",
        "        'verbose': -1,\n",
        "        'random_state': 42,\n",
        "        'n_estimators': 2000\n",
        "    }\n",
        "\n",
        "    feature_cols=[col for col in train_data.columns if col != 'Weekly_Sales']\n",
        "    X=train_data[feature_cols]\n",
        "    y=train_data['Weekly_Sales']\n",
        "\n",
        "    weights=train_data['IsHoliday'].map({True: 5, False: 1}).values\n",
        "\n",
        "    splits=time_series_split_walmart(train_data, n_splits=5)\n",
        "    cv_scores=[]\n",
        "    wmae_scores=[]\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(splits):\n",
        "        X_train_fold=X.iloc[train_idx]\n",
        "        y_train_fold=y.iloc[train_idx]\n",
        "        X_val_fold=X.iloc[val_idx]\n",
        "        y_val_fold=y.iloc[val_idx]\n",
        "        weights_val=weights[val_idx]\n",
        "\n",
        "        val_data_with_target=train_data.iloc[val_idx]\n",
        "\n",
        "        preprocessor=DataPreprocessor(\n",
        "            stores_df=stores_df,\n",
        "            features_df=features_df,\n",
        "            lag_features=[1, 2, 4, 8, 12],\n",
        "            rolling_windows=[4, 8, 12]\n",
        "        )\n",
        "\n",
        "        X_train_processed=preprocessor.fit(X_train_fold, y_train_fold).transform(X_train_fold)\n",
        "\n",
        "        X_val_processed=preprocessor.transform(val_data_with_target)\n",
        "\n",
        "        if 'Weekly_Sales' in X_val_processed.columns:\n",
        "            X_val_processed=X_val_processed.drop('Weekly_Sales', axis=1)\n",
        "\n",
        "        model=lgb.LGBMRegressor(**lgb_params)\n",
        "        model.fit(X_train_processed, y_train_fold,\n",
        "                 eval_set=[(X_val_processed, y_val_fold)],\n",
        "                 callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)])\n",
        "\n",
        "        y_pred=model.predict(X_val_processed)\n",
        "\n",
        "        y_pred=np.maximum(y_pred, 0)\n",
        "\n",
        "        mae=mean_absolute_error(y_val_fold, y_pred)\n",
        "        rmse=np.sqrt(mean_squared_error(y_val_fold, y_pred))\n",
        "        r2=r2_score(y_val_fold, y_pred)\n",
        "        wmae=wmae_score(y_val_fold, y_pred, weights_val)\n",
        "\n",
        "        cv_scores.append({'fold': fold, 'mae': mae, 'rmse': rmse, 'r2': r2, 'wmae': wmae})\n",
        "        wmae_scores.append(wmae)\n",
        "\n",
        "        print(f\"  MAE: {mae:.2f}, RMSE: {rmse:.2f}, R2: {r2:.4f}, WMAE: {wmae:.2f}\")\n",
        "\n",
        "    avg_mae=np.mean([score['mae'] for score in cv_scores])\n",
        "    avg_rmse=np.mean([score['rmse'] for score in cv_scores])\n",
        "    avg_r2=np.mean([score['r2'] for score in cv_scores])\n",
        "    avg_wmae=np.mean(wmae_scores)\n",
        "\n",
        "    print(f\"CV results:\")\n",
        "    print(f\"average MAE: {avg_mae:.2f}\")\n",
        "    print(f\"average RMSE: {avg_rmse:.2f}\")\n",
        "    print(f\"average R2: {avg_r2:.4f}\")\n",
        "    print(f\"average WMAE: {avg_wmae:.2f}\")\n",
        "\n",
        "    return cv_scores, avg_wmae"
      ],
      "metadata": {
        "id": "wlb8dHlLuTt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_data):\n",
        "    final_params={\n",
        "        'objective': 'regression',\n",
        "        'metric': 'mae',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': 63,\n",
        "        'learning_rate': 0.03,\n",
        "        'feature_fraction': 0.8,\n",
        "        'bagging_fraction': 0.8,\n",
        "        'bagging_freq': 5,\n",
        "        'max_depth': 8,\n",
        "        'min_child_samples': 20,\n",
        "        'reg_alpha': 0.1,\n",
        "        'reg_lambda': 0.1,\n",
        "        'verbose': -1,\n",
        "        'random_state': 42,\n",
        "        'n_estimators': 2000\n",
        "    }\n",
        "\n",
        "    pipeline=Pipeline([\n",
        "        ('preprocessor', DataPreprocessor(\n",
        "            stores_df=stores_df,\n",
        "            features_df=features_df,\n",
        "            lag_features=[1, 2, 4, 8, 12],\n",
        "            rolling_windows=[4, 8, 12]\n",
        "        )),\n",
        "        ('model', lgb.LGBMRegressor(**final_params))\n",
        "    ])\n",
        "\n",
        "    feature_cols=[col for col in train_data.columns if col != 'Weekly_Sales']\n",
        "    X_train=train_data[feature_cols]\n",
        "    y_train=train_data['Weekly_Sales']\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    train_pred=pipeline.predict(X_train)\n",
        "    train_pred=np.maximum(train_pred, 0)\n",
        "\n",
        "    mae=mean_absolute_error(y_train, train_pred)\n",
        "    rmse=np.sqrt(mean_squared_error(y_train, train_pred))\n",
        "    r2=r2_score(y_train, train_pred)\n",
        "\n",
        "    print(f\"model training metrics:\")\n",
        "    print(f\"MAE: {mae:.2f}, RMSE: {rmse:.2f}, R2: {r2:.4f}\")\n",
        "\n",
        "    return pipeline"
      ],
      "metadata": {
        "id": "HzN5fu6-udZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=train_df.drop('Weekly_Sales', axis=1)\n",
        "y_train=train_df['Weekly_Sales']\n",
        "\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Target shape: {y_train.shape}\")\n",
        "\n",
        "cv_scores, avg_wmae=run_cross_validation(train_df)\n",
        "\n",
        "my_pipeline=train_model(train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzSjhtCiunpm",
        "outputId": "5588aaf2-2023-44a6-b32d-86a81f200139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (420285, 4)\n",
            "Target shape: (420285,)\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's l1: 15098.8\n",
            "  MAE: 15098.83, RMSE: 23202.30, R2: 0.0001, WMAE: 15665.83\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's l1: 15135.9\n",
            "  MAE: 15135.90, RMSE: 22604.59, R2: -0.0006, WMAE: 14980.71\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[2]\tvalid_0's l1: 15008.9\n",
            "  MAE: 15008.94, RMSE: 21887.28, R2: -0.0003, WMAE: 15055.80\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's l1: 15772.4\n",
            "  MAE: 15772.36, RMSE: 24701.07, R2: -0.0010, WMAE: 16078.85\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's l1: 15199.8\n",
            "  MAE: 15199.76, RMSE: 22066.79, R2: -0.0002, WMAE: 15265.65\n",
            "CV results:\n",
            "average MAE: 15243.16\n",
            "average RMSE: 22892.41\n",
            "average R2: -0.0004\n",
            "average WMAE: 15409.37\n",
            "model training metrics:\n",
            "MAE: 1294.69, RMSE: 2402.67, R2: 0.9888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions=my_pipeline.predict(test_df)\n",
        "test_predictions=np.maximum(test_predictions, 0)"
      ],
      "metadata": {
        "id": "FUHYmr_0uu_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_submission=test_df[['Store', 'Dept', 'Date']].copy()\n",
        "test_submission['Weekly_Sales']=test_predictions\n",
        "\n",
        "test_submission['Date_str']=pd.to_datetime(test_submission['Date']).dt.strftime('%Y-%m-%d')\n",
        "test_submission['Id']=(test_submission['Store'].astype(str)+'_' +\n",
        "                       test_submission['Dept'].astype(str)+'_' +\n",
        "                       test_submission['Date_str'])\n",
        "\n",
        "submission=test_submission[['Id', 'Weekly_Sales']].copy()\n",
        "\n",
        "submission_path=f\"{FOLDERNAME}/submissions/lightgbm_submission.csv\"\n",
        "submission.to_csv(submission_path, index=False)\n",
        "\n",
        "print(f\"submission saved to: {submission_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPvExjopu2MR",
        "outputId": "7ea16040-a62a-401e-a301-ce44bab5cc25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission saved to: /content/drive/MyDrive/ML_final_project/lightgbm_submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path=f\"{FOLDERNAME}/submissions/lightgbm_pipeline.pkl\"\n",
        "joblib.dump(my_pipeline, model_path)\n",
        "print(f\"pipeline saved to: {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEJWYnmgu_w0",
        "outputId": "7d77652e-8a25-448f-c1bd-53a15066f450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pipeline saved to: /content/drive/MyDrive/ML_final_project/lightgbm_pipeline.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"submission shape: {submission.shape}\")\n",
        "print(f\"required columns: {list(submission.columns)}\")\n",
        "print(f\"no missing values: {submission.isnull().sum().sum() == 0}\")\n",
        "print(f\"no negative predictions: {(submission['Weekly_Sales']>=0).all()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Adh5h2yQw3-y",
        "outputId": "3c3ca0d5-b1b1-44ea-f77d-b1c6be8aaad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission shape: (115064, 2)\n",
            "required columns: ['Id', 'Weekly_Sales']\n",
            "no missing values: True\n",
            "no negative predictions: True\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}