{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36266,
     "status": "ok",
     "timestamp": 1752577584155,
     "user": {
      "displayName": "Salome Karaulashvili",
      "userId": "06321350953148677806"
     },
     "user_tz": -240
    },
    "id": "RuwPZtYUU0Wc",
    "outputId": "aa23c0a8-927e-43d5-9571-e395715022d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import sys\n",
    "FOLDERNAME='ML_final_project'\n",
    "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZQIJX-b36s7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scripts.data_processor import DataPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37950,
     "status": "ok",
     "timestamp": 1752577629644,
     "user": {
      "displayName": "Salome Karaulashvili",
      "userId": "06321350953148677806"
     },
     "user_tz": -240
    },
    "id": "oEJ9TUTUwsWh",
    "outputId": "0fdf9e27-e167-4db0-b738-9a85524d9096"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.3/26.3 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m741.4/741.4 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.4 --force-reinstall -q\n",
    "!pip install mlflow==2.15.1 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331,
     "referenced_widgets": [
      "3510dbd1012046728dd5f7555510d86e",
      "02e6996a82db47d0987939edfe2b4b2e"
     ]
    },
    "executionInfo": {
     "elapsed": 83610,
     "status": "ok",
     "timestamp": 1752577713280,
     "user": {
      "displayName": "Salome Karaulashvili",
      "userId": "06321350953148677806"
     },
     "user_tz": -240
    },
    "id": "8D8M27GgDNFt",
    "outputId": "d131994d-0fb0-4e3b-e342-5375fe7f6ae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">❗❗❗ AUTHORIZATION REQUIRED ❗❗❗</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                       \u001b[1m❗❗❗ AUTHORIZATION REQUIRED ❗❗❗\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Open the following link in your browser to authorize the client:\n",
      "https://dagshub.com/login/oauth/authorize?state=d2f01277-7e9d-496f-961f-dfe8c8d06cbf&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=9ac2b6d499d23f900ed3faf81dccded798de4b21303235add62ec9ccc76d48e7\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3510dbd1012046728dd5f7555510d86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as skara-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as skara-\u001b[1;36m21\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"skara-21/ML_Final_Project\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"skara-21/ML_Final_Project\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository skara-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>/ML_Final_Project initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository skara-\u001b[1;36m21\u001b[0m/ML_Final_Project initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 'LightGBM_Training' set with ID: 1\n"
     ]
    }
   ],
   "source": [
    "!pip install dagshub mlflow -q\n",
    "\n",
    "import dagshub\n",
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.exceptions import MlflowException\n",
    "from mlflow.entities import Experiment\n",
    "from mlflow.entities.lifecycle_stage import LifecycleStage\n",
    "\n",
    "dagshub.init(repo_owner='skara-21', repo_name='ML_Final_Project', mlflow=True)\n",
    "\n",
    "mlflow.set_tracking_uri('https://dagshub.com/skara-21/ML_Final_Project.mlflow')\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment_name = \"LightGBM_Training\"\n",
    "\n",
    "try:\n",
    "    experiment = client.get_experiment_by_name(experiment_name)\n",
    "    if experiment:\n",
    "        # If it exists and is deleted, restore it or permanently delete it\n",
    "        if experiment.lifecycle_stage == LifecycleStage.DELETED:\n",
    "            print(f\"Experiment '{experiment_name}' is deleted. Attempting to restore...\")\n",
    "            try:\n",
    "                client.restore_experiment(experiment.experiment_id)\n",
    "                print(f\"Experiment '{experiment_name}' restored.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to restore experiment: {e}. Permanently deleting...\")\n",
    "                client.delete_experiment(experiment.experiment_id, True)\n",
    "                print(f\"Experiment '{experiment_name}' permanently deleted.\")\n",
    "                # Now create the experiment again\n",
    "                experiment = None # Set experiment to None to trigger creation\n",
    "\n",
    "\n",
    "    if experiment is None:\n",
    "         # If experiment does not exist or was permanently deleted, create it\n",
    "        experiment_id = client.create_experiment(experiment_name)\n",
    "        print(f\"Experiment '{experiment_name}' created with ID: {experiment_id}\")\n",
    "    else:\n",
    "        # If experiment exists and is active, set it\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "        experiment_id = experiment.experiment_id\n",
    "        print(f\"Experiment '{experiment_name}' set with ID: {experiment_id}\")\n",
    "\n",
    "except MlflowException as e:\n",
    "    print(f\"An MLflow error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1752577713307,
     "user": {
      "displayName": "Salome Karaulashvili",
      "userId": "06321350953148677806"
     },
     "user_tz": -240
    },
    "id": "mlflow_setup",
    "outputId": "492fc92d-9ffe-42ee-a448-76a89b76edbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow experiment set to: LightGBM_Training\n",
      "MLflow tracking URI: https://dagshub.com/skara-21/ML_Final_Project.mlflow\n"
     ]
    }
   ],
   "source": [
    "print(f\"MLflow experiment set to: LightGBM_Training\")\n",
    "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4wo5dWZuPb4"
   },
   "outputs": [],
   "source": [
    "def wmae_score(y_true, y_pred, weights):\n",
    "    return np.sum(weights * np.abs(y_true - y_pred)) / np.sum(weights)\n",
    "\n",
    "def check_missing(df, dataset_name):\n",
    "    \"\"\"Check missing values in dataframe\"\"\"\n",
    "    missing_data = {}\n",
    "    for col in df.columns:\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            missing_data[col] = missing_count\n",
    "            print(f\"{dataset_name} - {col}: {missing_count} missing values\")\n",
    "    return missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3414,
     "status": "ok",
     "timestamp": 1752577716734,
     "user": {
      "displayName": "Salome Karaulashvili",
      "userId": "06321350953148677806"
     },
     "user_tz": -240
    },
    "id": "qxocGDZAt18t",
    "outputId": "1abebefd-1c26-4220-e4b7-d51daeda4ba3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/15 11:08:44 INFO mlflow.tracking._tracking_service.client: 🏃 View run LightGBM_Data_Loading at: https://dagshub.com/skara-21/ML_Final_Project.mlflow/#/experiments/1/runs/081e62ae1bd942b5ad9dc194d86d0887.\n",
      "2025/07/15 11:08:44 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/skara-21/ML_Final_Project.mlflow/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded:\n",
      "Train: (421570, 5)\n",
      "Test: (115064, 4)\n",
      "Features: (8190, 12)\n",
      "Stores: (45, 3)\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"LightGBM_Data_Loading\") as run:\n",
    "    FOLDERNAME='/content/drive/MyDrive/ML_final_project'\n",
    "    DATAPATH=f'{FOLDERNAME}/data/'\n",
    "\n",
    "    train_df=pd.read_csv(DATAPATH+'train.csv')\n",
    "    test_df=pd.read_csv(DATAPATH+'test.csv')\n",
    "    features_df=pd.read_csv(DATAPATH+'features.csv')\n",
    "    stores_df=pd.read_csv(DATAPATH+'stores.csv')\n",
    "\n",
    "    mlflow.log_metric(\"initial_train_rows\", train_df.shape[0])\n",
    "    mlflow.log_metric(\"initial_train_cols\", train_df.shape[1])\n",
    "    mlflow.log_metric(\"initial_test_rows\", test_df.shape[0])\n",
    "    mlflow.log_metric(\"initial_test_cols\", test_df.shape[1])\n",
    "    mlflow.log_metric(\"features_rows\", features_df.shape[0])\n",
    "    mlflow.log_metric(\"stores_rows\", stores_df.shape[0])\n",
    "\n",
    "    print(f\"Data loaded:\")\n",
    "    print(f\"Train: {train_df.shape}\")\n",
    "    print(f\"Test: {test_df.shape}\")\n",
    "    print(f\"Features: {features_df.shape}\")\n",
    "    print(f\"Stores: {stores_df.shape}\")\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1359,
     "status": "ok",
     "timestamp": 1752577718098,
     "user": {
      "displayName": "Salome Karaulashvili",
      "userId": "06321350953148677806"
     },
     "user_tz": -240
    },
    "id": "s4mfpkRZuGNn",
    "outputId": "9f5155a8-c38d-43e3-f0bf-e271654659e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/15 11:08:44 INFO mlflow.tracking._tracking_service.client: 🏃 View run LightGBM_Cleaning at: https://dagshub.com/skara-21/ML_Final_Project.mlflow/#/experiments/1/runs/b8dae086d2814233a0188556e90aeef5.\n",
      "2025/07/15 11:08:44 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/skara-21/ML_Final_Project.mlflow/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1285 rows with negative sales\n",
      "Final training rows: 420285\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"LightGBM_Cleaning\") as run:\n",
    "    features_df['Date']=pd.to_datetime(features_df['Date'])\n",
    "    train_df['Date']=pd.to_datetime(train_df['Date'])\n",
    "    test_df['Date']=pd.to_datetime(test_df['Date'])\n",
    "\n",
    "    initial_rows=len(train_df)\n",
    "    train_df=train_df[train_df['Weekly_Sales']>=0].reset_index(drop=True)\n",
    "    removed_ones = initial_rows - len(train_df)\n",
    "\n",
    "    mlflow.log_metric(\"negative_sales_removed\", removed_ones)\n",
    "    mlflow.log_metric(\"cleaned_train_rows\", len(train_df))\n",
    "\n",
    "    print(f\"Removed {removed_ones} rows with negative sales\")\n",
    "    print(f\"Final training rows: {len(train_df)}\")\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15972,
     "status": "ok",
     "timestamp": 1752577734076,
     "user": {
      "displayName": "Salome Karaulashvili",
      "userId": "06321350953148677806"
     },
     "user_tz": -240
    },
    "id": "missing_values_check",
    "outputId": "8427f231-b79a-4bd1-f50a-e9cd39cb6b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Merged - MarkDown1: 270085 missing values\n",
      "Train Merged - MarkDown2: 309367 missing values\n",
      "Train Merged - MarkDown3: 283618 missing values\n",
      "Train Merged - MarkDown4: 285750 missing values\n",
      "Train Merged - MarkDown5: 269337 missing values\n",
      "Test Merged - MarkDown1: 149 missing values\n",
      "Test Merged - MarkDown2: 28627 missing values\n",
      "Test Merged - MarkDown3: 9829 missing values\n",
      "Test Merged - MarkDown4: 12888 missing values\n",
      "Test Merged - CPI: 38162 missing values\n",
      "Test Merged - Unemployment: 38162 missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/15 11:09:00 INFO mlflow.tracking._tracking_service.client: 🏃 View run LightGBM_Missing_Values at: https://dagshub.com/skara-21/ML_Final_Project.mlflow/#/experiments/1/runs/fb1892f11aec4081b0b5b65a21f91d23.\n",
      "2025/07/15 11:09:00 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/skara-21/ML_Final_Project.mlflow/#/experiments/1.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"LightGBM_Missing_Values\") as run:\n",
    "    train_merged = train_df.merge(stores_df, on='Store', how='left')\n",
    "    train_merged = train_merged.merge(features_df, on=['Store', 'Date'], how='left')\n",
    "\n",
    "    test_merged = test_df.merge(stores_df, on='Store', how='left')\n",
    "    test_merged = test_merged.merge(features_df, on=['Store', 'Date'], how='left')\n",
    "\n",
    "    train_missing = check_missing(train_merged, \"Train Merged\")\n",
    "    test_missing = check_missing(test_merged, \"Test Merged\")\n",
    "\n",
    "    for col, count in train_missing.items():\n",
    "        mlflow.log_metric(f\"train_missing_{col}\", count)\n",
    "    for col, count in test_missing.items():\n",
    "        mlflow.log_metric(f\"test_missing_{col}\", count)\n",
    "\n",
    "    mlflow.log_metric(\"total_train_missing_columns\", len(train_missing))\n",
    "    mlflow.log_metric(\"total_test_missing_columns\", len(test_missing))\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cneh4z3huLps"
   },
   "outputs": [],
   "source": [
    "def time_series_split_walmart(train_data, n_splits=5):\n",
    "    train_data=train_data.sort_values('Date')\n",
    "    dates=train_data['Date'].unique()\n",
    "    dates=np.sort(dates)\n",
    "\n",
    "    split_size=len(dates)//(n_splits+1)\n",
    "    splits=[]\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        train_end_idx=(i+1) * split_size\n",
    "        val_start_idx=train_end_idx\n",
    "        val_end_idx=train_end_idx+split_size\n",
    "\n",
    "        train_dates=dates[:train_end_idx]\n",
    "        val_dates=dates[val_start_idx:val_end_idx]\n",
    "\n",
    "        train_idx=train_data[train_data['Date'].isin(train_dates)].index\n",
    "        val_idx=train_data[train_data['Date'].isin(val_dates)].index\n",
    "\n",
    "        splits.append((train_idx, val_idx))\n",
    "\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlb8dHlLuTt-"
   },
   "outputs": [],
   "source": [
    "def run_cross_validation(train_data):\n",
    "    with mlflow.start_run(run_name=\"LightGBM_Cross_Validation\") as run:\n",
    "        lgb_params={\n",
    "            'objective': 'regression',\n",
    "            'metric': 'mae',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 63,\n",
    "            'learning_rate': 0.03,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'max_depth': 8,\n",
    "            'min_child_samples': 20,\n",
    "            'reg_alpha': 0.1,\n",
    "            'reg_lambda': 0.1,\n",
    "            'verbose': -1,\n",
    "            'random_state': 42,\n",
    "            'n_estimators': 2000\n",
    "        }\n",
    "\n",
    "        for param, value in lgb_params.items():\n",
    "            mlflow.log_param(f\"cv_{param}\", value)\n",
    "\n",
    "        mlflow.log_param(\"cv_splits\", 5)\n",
    "        mlflow.log_param(\"cv_strategy\", \"TimeSeriesSplit\")\n",
    "\n",
    "        feature_cols=[col for col in train_data.columns if col != 'Weekly_Sales']\n",
    "        X=train_data[feature_cols]\n",
    "        y=train_data['Weekly_Sales']\n",
    "\n",
    "        weights=train_data['IsHoliday'].map({True: 5, False: 1}).values\n",
    "\n",
    "        splits=time_series_split_walmart(train_data, n_splits=5)\n",
    "        cv_scores=[]\n",
    "        wmae_scores=[]\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(splits):\n",
    "            print(f\"Working on fold {fold + 1}/5\")\n",
    "\n",
    "            X_train_fold=X.iloc[train_idx]\n",
    "            y_train_fold=y.iloc[train_idx]\n",
    "            X_val_fold=X.iloc[val_idx]\n",
    "            y_val_fold=y.iloc[val_idx]\n",
    "            weights_val=weights[val_idx]\n",
    "\n",
    "            val_data_with_target=train_data.iloc[val_idx]\n",
    "\n",
    "            preprocessor=DataPreprocessor(\n",
    "                stores_df=stores_df,\n",
    "                features_df=features_df,\n",
    "                lag_features=[1, 2, 4, 8, 12],\n",
    "                rolling_windows=[4, 8, 12]\n",
    "            )\n",
    "\n",
    "            X_train_processed=preprocessor.fit(X_train_fold, y_train_fold).transform(X_train_fold)\n",
    "            X_val_processed=preprocessor.transform(val_data_with_target)\n",
    "\n",
    "            if 'Weekly_Sales' in X_val_processed.columns:\n",
    "                X_val_processed=X_val_processed.drop('Weekly_Sales', axis=1)\n",
    "\n",
    "            model=lgb.LGBMRegressor(**lgb_params)\n",
    "            model.fit(X_train_processed, y_train_fold,\n",
    "                     eval_set=[(X_val_processed, y_val_fold)],\n",
    "                     callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)])\n",
    "\n",
    "            y_pred=model.predict(X_val_processed)\n",
    "            y_pred=np.maximum(y_pred, 0)\n",
    "\n",
    "            mae=mean_absolute_error(y_val_fold, y_pred)\n",
    "            rmse=np.sqrt(mean_squared_error(y_val_fold, y_pred))\n",
    "            r2=r2_score(y_val_fold, y_pred)\n",
    "            wmae=wmae_score(y_val_fold, y_pred, weights_val)\n",
    "\n",
    "            cv_scores.append({'fold': fold, 'mae': mae, 'rmse': rmse, 'r2': r2, 'wmae': wmae})\n",
    "            wmae_scores.append(wmae)\n",
    "\n",
    "            mlflow.log_metric(f\"fold_{fold}_mae\", mae)\n",
    "            mlflow.log_metric(f\"fold_{fold}_rmse\", rmse)\n",
    "            mlflow.log_metric(f\"fold_{fold}_r2\", r2)\n",
    "            mlflow.log_metric(f\"fold_{fold}_wmae\", wmae)\n",
    "\n",
    "            print(f\"  MAE: {mae:.2f}, RMSE: {rmse:.2f}, R2: {r2:.4f}, WMAE: {wmae:.2f}\")\n",
    "\n",
    "        avg_mae=np.mean([score['mae'] for score in cv_scores])\n",
    "        avg_rmse=np.mean([score['rmse'] for score in cv_scores])\n",
    "        avg_r2=np.mean([score['r2'] for score in cv_scores])\n",
    "        avg_wmae=np.mean(wmae_scores)\n",
    "\n",
    "        mlflow.log_metric(\"cv_avg_mae\", avg_mae)\n",
    "        mlflow.log_metric(\"cv_avg_rmse\", avg_rmse)\n",
    "        mlflow.log_metric(\"cv_avg_r2\", avg_r2)\n",
    "        mlflow.log_metric(\"cv_avg_wmae\", avg_wmae)\n",
    "\n",
    "        print(f\"\\nCV results:\")\n",
    "        print(f\"Average MAE: {avg_mae:.2f}\")\n",
    "        print(f\"Average RMSE: {avg_rmse:.2f}\")\n",
    "        print(f\"Average R2: {avg_r2:.4f}\")\n",
    "        print(f\"Average WMAE: {avg_wmae:.2f}\")\n",
    "\n",
    "    mlflow.end_run()\n",
    "    return cv_scores, avg_wmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HzN5fu6-udZH"
   },
   "outputs": [],
   "source": [
    "def train_model(train_data):\n",
    "    with mlflow.start_run(run_name=\"LightGBM_Final_Training\") as run:\n",
    "        final_params={\n",
    "            'objective': 'regression',\n",
    "            'metric': 'mae',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 63,\n",
    "            'learning_rate': 0.03,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'max_depth': 8,\n",
    "            'min_child_samples': 20,\n",
    "            'reg_alpha': 0.1,\n",
    "            'reg_lambda': 0.1,\n",
    "            'verbose': -1,\n",
    "            'random_state': 42,\n",
    "            'n_estimators': 2000\n",
    "        }\n",
    "\n",
    "        for param, value in final_params.items():\n",
    "            mlflow.log_param(param, value)\n",
    "\n",
    "        mlflow.log_param(\"lag_features\", [1, 2, 4, 8, 12])\n",
    "        mlflow.log_param(\"rolling_windows\", [4, 8, 12])\n",
    "        mlflow.log_param(\"preprocessor\", \"DataPreprocessor\")\n",
    "\n",
    "        pipeline=Pipeline([\n",
    "            ('preprocessor', DataPreprocessor(\n",
    "                stores_df=stores_df,\n",
    "                features_df=features_df,\n",
    "                lag_features=[1, 2, 4, 8, 12],\n",
    "                rolling_windows=[4, 8, 12]\n",
    "            )),\n",
    "            ('model', lgb.LGBMRegressor(**final_params))\n",
    "        ])\n",
    "\n",
    "        feature_cols=[col for col in train_data.columns if col != 'Weekly_Sales']\n",
    "        X_train=train_data[feature_cols]\n",
    "        y_train=train_data['Weekly_Sales']\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        train_pred=pipeline.predict(X_train)\n",
    "        train_pred=np.maximum(train_pred, 0)\n",
    "\n",
    "        mae=mean_absolute_error(y_train, train_pred)\n",
    "        rmse=np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "        r2=r2_score(y_train, train_pred)\n",
    "\n",
    "        mlflow.log_metric(\"final_mae\", mae)\n",
    "        mlflow.log_metric(\"final_rmse\", rmse)\n",
    "        mlflow.log_metric(\"final_r2\", r2)\n",
    "\n",
    "        lgb_model = pipeline.named_steps['model']\n",
    "        mlflow.lightgbm.log_model(\n",
    "            lgb_model,\n",
    "            \"lightgbm_model\",\n",
    "            registered_model_name=\"walmart_lightgbm_model\"\n",
    "        )\n",
    "\n",
    "\n",
    "        print(f\"Model training metrics:\")\n",
    "        print(f\"MAE: {mae:.2f}, RMSE: {rmse:.2f}, R2: {r2:.4f}\")\n",
    "\n",
    "    mlflow.end_run()\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12711,
     "status": "ok",
     "timestamp": 1752577747057,
     "user": {
      "displayName": "Salome Karaulashvili",
      "userId": "06321350953148677806"
     },
     "user_tz": -240
    },
    "id": "feature_engineering_log",
    "outputId": "52e515a0-c54b-4e3a-f00a-e2caf484713f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering parameters logged\n",
      "Training data shape: (420285, 5)\n",
      "Test data shape: (115064, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/15 11:09:13 INFO mlflow.tracking._tracking_service.client: 🏃 View run LightGBM_Feature_Engineering at: https://dagshub.com/skara-21/ML_Final_Project.mlflow/#/experiments/1/runs/4d5d986321ff4666b965dd0fa10317f1.\n",
      "2025/07/15 11:09:13 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/skara-21/ML_Final_Project.mlflow/#/experiments/1.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"LightGBM_Feature_Engineering\") as run:\n",
    "\n",
    "    mlflow.log_param(\"time_features_added\", [\"Day\", \"Week\", \"Month\", \"Year\", \"Quarter\", \"DayOfYear\", \"WeekOfMonth\"])\n",
    "    mlflow.log_param(\"lag_features\", [1, 2, 4, 8, 12])\n",
    "    mlflow.log_param(\"rolling_windows\", [4, 8, 12])\n",
    "    mlflow.log_param(\"categorical_encoding\", \"LabelEncoder\")\n",
    "    mlflow.log_param(\"negative_sales_handling\", \"removed\")\n",
    "    mlflow.log_param(\"missing_value_strategy\", \"median_fill\")\n",
    "\n",
    "    print(f\"Feature engineering parameters logged\")\n",
    "    print(f\"Training data shape: {train_df.shape}\")\n",
    "    print(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "    mlflow.log_metric(\"processed_train_rows\", train_df.shape[0])\n",
    "    mlflow.log_metric(\"processed_train_cols\", train_df.shape[1])\n",
    "    mlflow.log_metric(\"processed_test_rows\", test_df.shape[0])\n",
    "    mlflow.log_metric(\"processed_test_cols\", test_df.shape[1])\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 338035,
     "status": "ok",
     "timestamp": 1752579114839,
     "user": {
      "displayName": "Salome Karaulashvili",
      "userId": "06321350953148677806"
     },
     "user_tz": -240
    },
    "id": "ZzSjhtCiunpm",
    "outputId": "0b9b016d-cc5e-4e9a-d8ed-17722fbdabc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STARTING LIGHTGBM EXPERIMENT\n",
      "==================================================\n",
      "Training data shape: (420285, 4)\n",
      "Target shape: (420285,)\n",
      "\n",
      "Running cross validation...\n",
      "Working on fold 1/5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's l1: 15098.8\n",
      "  MAE: 15098.83, RMSE: 23202.30, R2: 0.0001, WMAE: 15665.83\n",
      "Working on fold 2/5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's l1: 15135.9\n",
      "  MAE: 15135.90, RMSE: 22604.59, R2: -0.0006, WMAE: 14980.71\n",
      "Working on fold 3/5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's l1: 15008.9\n",
      "  MAE: 15008.94, RMSE: 21887.28, R2: -0.0003, WMAE: 15055.80\n",
      "Working on fold 4/5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's l1: 15772.4\n",
      "  MAE: 15772.36, RMSE: 24701.07, R2: -0.0010, WMAE: 16078.85\n",
      "Working on fold 5/5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's l1: 15199.8\n",
      "  MAE: 15199.76, RMSE: 22066.79, R2: -0.0002, WMAE: 15265.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/15 11:20:13 INFO mlflow.tracking._tracking_service.client: 🏃 View run LightGBM_Cross_Validation at: https://dagshub.com/skara-21/ML_Final_Project.mlflow/#/experiments/1/runs/0f57ec90235243ec8a37a49c1535cd18.\n",
      "2025/07/15 11:20:13 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/skara-21/ML_Final_Project.mlflow/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV results:\n",
      "Average MAE: 15243.16\n",
      "Average RMSE: 22892.41\n",
      "Average R2: -0.0004\n",
      "Average WMAE: 15409.37\n",
      "\n",
      "Training final model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=4, connect=5, read=4, redirect=5, status=5)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /skara-21/ML_Final_Project.mlflow/api/2.0/mlflow/runs/log-metric\n",
      "2025/07/15 11:31:59 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpki9z_xny/model, flavor: lightgbm). Fall back to return ['lightgbm==4.5.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "Successfully registered model 'walmart_lightgbm_model'.\n",
      "2025/07/15 11:32:02 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: walmart_lightgbm_model, version 1\n",
      "Created version '1' of model 'walmart_lightgbm_model'.\n",
      "2025/07/15 11:32:02 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2025/07/15 11:32:02 INFO mlflow.tracking._tracking_service.client: 🏃 View run LightGBM_Final_Training at: https://dagshub.com/skara-21/ML_Final_Project.mlflow/#/experiments/1/runs/94709e7abcc349fe9977c4134495c36b.\n",
      "2025/07/15 11:32:02 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/skara-21/ML_Final_Project.mlflow/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training metrics:\n",
      "MAE: 1294.69, RMSE: 2402.67, R2: 0.9888\n"
     ]
    }
   ],
   "source": [
    "print(\"STARTING LIGHTGBM EXPERIMENT\")\n",
    "\n",
    "X_train=train_df.drop('Weekly_Sales', axis=1)\n",
    "y_train=train_df['Weekly_Sales']\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Target shape: {y_train.shape}\")\n",
    "\n",
    "print(\"Running cross validation...\")\n",
    "cv_scores, avg_wmae=run_cross_validation(train_df)\n",
    "\n",
    "print(\"Training final model...\")\n",
    "my_pipeline=train_model(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 88400,
     "status": "ok",
     "timestamp": 1752579203259,
     "user": {
      "displayName": "Salome Karaulashvili",
      "userId": "06321350953148677806"
     },
     "user_tz": -240
    },
    "id": "FUHYmr_0uu_b",
    "outputId": "edaa132c-5cb7-4d97-8771-0566aa661280"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "CREATING SUBMISSION FILE\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/15 11:33:30 INFO mlflow.tracking._tracking_service.client: 🏃 View run LightGBM_Submission_Generation at: https://dagshub.com/skara-21/ML_Final_Project.mlflow/#/experiments/1/runs/31bd114cd96d4e949fd254dc95a17cd6.\n",
      "2025/07/15 11:33:30 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/skara-21/ML_Final_Project.mlflow/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to: /content/drive/MyDrive/ML_final_project/submissions/lightgbm_submission.csv\n",
      "Submission shape: (115064, 2)\n",
      "\n",
      "First 10 rows of submission:\n",
      "               Id  Weekly_Sales\n",
      "0  1_1_2012-11-02  33919.338495\n",
      "1  1_1_2012-11-09  22639.544689\n",
      "2  1_1_2012-11-16  20724.343998\n",
      "3  1_1_2012-11-23  20847.508884\n",
      "4  1_1_2012-11-30  25396.228025\n",
      "5  1_1_2012-12-07  30506.103265\n",
      "6  1_1_2012-12-14  43249.528919\n",
      "7  1_1_2012-12-21  54777.411543\n",
      "8  1_1_2012-12-28  29845.165822\n",
      "9  1_1_2013-01-04  17231.132986\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"LightGBM_Submission_Generation\") as run:\n",
    "    print(\"CREATING SUBMISSION FILE\")\n",
    "\n",
    "    test_predictions=my_pipeline.predict(test_df)\n",
    "    test_predictions=np.maximum(test_predictions, 0)\n",
    "\n",
    "    test_submission=test_df[['Store', 'Dept', 'Date']].copy()\n",
    "    test_submission['Weekly_Sales']=test_predictions\n",
    "\n",
    "    test_submission['Date_str']=pd.to_datetime(test_submission['Date']).dt.strftime('%Y-%m-%d')\n",
    "    test_submission['Id']=(test_submission['Store'].astype(str)+'_' +\n",
    "                           test_submission['Dept'].astype(str)+'_' +\n",
    "                           test_submission['Date_str'])\n",
    "\n",
    "    submission=test_submission[['Id', 'Weekly_Sales']].copy()\n",
    "\n",
    "    submission_path=f\"{FOLDERNAME}/submissions/lightgbm_submission.csv\"\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "\n",
    "    mlflow.log_artifact(submission_path)\n",
    "    mlflow.log_metric(\"submission_rows\", len(submission))\n",
    "    mlflow.log_metric(\"prediction_mean\", np.mean(test_predictions))\n",
    "    mlflow.log_metric(\"prediction_std\", np.std(test_predictions))\n",
    "    mlflow.log_metric(\"prediction_min\", np.min(test_predictions))\n",
    "    mlflow.log_metric(\"prediction_max\", np.max(test_predictions))\n",
    "\n",
    "    print(f\"Submission saved to: {submission_path}\")\n",
    "    print(f\"Submission shape: {submission.shape}\")\n",
    "    print(\"First 10 rows of submission:\")\n",
    "    print(submission.head(10))\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NEJWYnmgu_w0"
   },
   "outputs": [],
   "source": [
    "model_path=f\"{FOLDERNAME}/submissions/lightgbm_pipeline.pkl\"\n",
    "joblib.dump(my_pipeline, model_path)\n",
    "print(f\"Pipeline saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ეს იმიტომ რომ ლინკებს არ მიგდებდა MLFlow-სთვის"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1752579204334,
     "user": {
      "displayName": "Salome Karaulashvili",
      "userId": "06321350953148677806"
     },
     "user_tz": -240
    },
    "id": "mlflow_summary",
    "outputId": "b0b33f81-fb14-4d37-b9d9-0290db4f30b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLflow Tracking Information:\n",
      "Experiment Name: LightGBM_Training\n",
      "Tracking URI: https://dagshub.com/skara-21/ML_Final_Project.mlflow\n",
      "\n",
      "To view results, you can access MLflow UI or check the experiment in your MLflow server.\n",
      "\n",
      "Recent runs in this experiment:\n",
      "- LightGBM_Submission_Generation (Status: FINISHED)\n",
      "- LightGBM_Final_Training (Status: FINISHED)\n",
      "- LightGBM_Cross_Validation (Status: FINISHED)\n",
      "- LightGBM_Feature_Engineering (Status: FINISHED)\n",
      "- LightGBM_Missing_Values (Status: FINISHED)\n",
      "- LightGBM_Cleaning (Status: FINISHED)\n",
      "- LightGBM_Data_Loading (Status: FINISHED)\n"
     ]
    }
   ],
   "source": [
    "print(\"MLflow Tracking Information:\")\n",
    "print(f\"Experiment Name: LightGBM_Training\")\n",
    "print(f\"Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(\"To view results, you can access MLflow UI or check the experiment in your MLflow server.\")\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(\"LightGBM_Training\")\n",
    "if experiment:\n",
    "    runs = client.search_runs(experiment_ids=[experiment.experiment_id], max_results=10)\n",
    "    print(f\"Recent runs in this experiment:\")\n",
    "    for run in runs:\n",
    "        print(f\"- {run.info.run_name} (Status: {run.info.status})\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02e6996a82db47d0987939edfe2b4b2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3510dbd1012046728dd5f7555510d86e": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_02e6996a82db47d0987939edfe2b4b2e",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠧</span> Waiting for authorization\n</pre>\n",
         "text/plain": "\u001b[32m⠧\u001b[0m Waiting for authorization\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
