{"cells":[{"cell_type":"markdown","source":["# **Drive Access**"],"metadata":{"id":"pw1gz1zghM4A"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BsNMFvsLF44m"},"outputs":[],"source":["# Mount Google Drive and set paths\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","FOLDERNAME = '/content/drive/MyDrive/ML_final_project'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","DATAPATH = f'{FOLDERNAME}/data/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ffE2frNF41n"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.ndimage import shift\n","from sklearn.metrics import mean_squared_error as mse, mean_absolute_error as mae\n","from sklearn.preprocessing import StandardScaler\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","!pip install dagshub mlflow prophet -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EybAdCjrF4zD"},"outputs":[],"source":["import dagshub\n","import mlflow\n","import mlflow.sklearn\n","from mlflow.tracking import MlflowClient\n","from mlflow.models.signature import infer_signature\n","from prophet import Prophet"]},{"cell_type":"markdown","source":["# **MLflow Setup**"],"metadata":{"id":"5CLBreYdhRNY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pNeXbQa2F4v-"},"outputs":[],"source":["dagshub.init(repo_owner='kechik21', repo_name='ML_Final_Project', mlflow=True)\n","mlflow.set_tracking_uri('https://dagshub.com/kechik21/ML_Final_Project.mlflow')\n","\n","experiment_name = \"Prophet_Training\"\n","try:\n","    experiment_id = mlflow.create_experiment(experiment_name)\n","    print(f\"Created new experiment: {experiment_name}\")\n","except mlflow.exceptions.MlflowException:\n","    experiment = mlflow.get_experiment_by_name(experiment_name)\n","    experiment_id = experiment.experiment_id\n","    print(f\"Using existing experiment: {experiment_name}\")\n","\n","mlflow.set_experiment(experiment_name)\n","\n","print(\" MLflow setup complete!\")\n","print(\" Your experiments will be visible at:\")\n","print(\"   https://dagshub.com/kechik21/ML_Final_Project\")\n","print(f\" Current experiment: {experiment_name}\")"]},{"cell_type":"markdown","source":["# **Data Loading and Exploration**"],"metadata":{"id":"PZxsyaBjbyN-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0njVTKvVF4tT"},"outputs":[],"source":["with mlflow.start_run(run_name=\"Prophet_Data_Loading\"):\n","    print(\"Starting Data Loading and Initial Exploration...\")\n","\n","    #Load\n","    print(\"Loading datasets...\")\n","    train_df = pd.read_csv(DATAPATH + 'train.csv')\n","    test_df = pd.read_csv(DATAPATH + 'test.csv')\n","    features_df = pd.read_csv(DATAPATH + 'features.csv')\n","    stores_df = pd.read_csv(DATAPATH + 'stores.csv')\n","\n","\n","    mlflow.log_param(\"train_shape\", train_df.shape)\n","    mlflow.log_param(\"test_shape\", test_df.shape)\n","    mlflow.log_param(\"features_shape\", features_df.shape)\n","    mlflow.log_param(\"stores_shape\", stores_df.shape)\n","\n","    mlflow.log_param(\"unique_stores\", train_df['Store'].nunique())\n","    mlflow.log_param(\"unique_departments\", train_df['Dept'].nunique())\n","    mlflow.log_param(\"date_range_train\", f\"{train_df['Date'].min()} to {train_df['Date'].max()}\")\n","    mlflow.log_param(\"date_range_test\", f\"{test_df['Date'].min()} to {test_df['Date'].max()}\")\n","\n","    print(f\"Train data shape: {train_df.shape}\")\n","    print(f\"Test data shape: {test_df.shape}\")\n","    print(f\"Number of stores: {train_df['Store'].nunique()}\")\n","    print(f\"Number of departments: {train_df['Dept'].nunique()}\")\n","\n","    mlflow.log_text(\"Data loading completed successfully\", \"data_loading_status.txt\")"]},{"cell_type":"markdown","source":["# **Data Processing**"],"metadata":{"id":"LiV7COHlb2tI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"XYktvCvaF4qw"},"outputs":[],"source":["with mlflow.start_run(run_name=\"Prophet_Data_Preprocessing\"):\n","    print(\"\\nStarting Data Preprocessing...\")\n","\n","\n","    merged_1 = train_df.merge(stores_df, on=['Store'], how='left')\n","    train = merged_1.merge(features_df, on=['Store','Date','IsHoliday'], how='left')\n","\n","    merged_test = test_df.merge(stores_df, on=['Store'], how='left')\n","    test = merged_test.merge(features_df, on=['Store','Date','IsHoliday'], how='left')\n","\n","    train['sales'] = train['Weekly_Sales']\n","    train = train.drop('Weekly_Sales', axis=1)\n","\n","    mlflow.log_param(\"merge_strategy\", \"left_join\")\n","    mlflow.log_param(\"sales_column_renamed\", True)\n","    mlflow.log_param(\"missing_values_before\", train.isnull().sum().sum())\n","\n","    train = train.fillna(method='ffill').fillna(method='bfill')\n","    test = test.fillna(method='ffill').fillna(method='bfill')\n","\n","    mlflow.log_param(\"missing_values_after\", train.isnull().sum().sum())\n","    mlflow.log_param(\"preprocessing_complete\", True)\n","\n","    print(\"Data preprocessing completed\")\n","    print(f\"Final train shape: {train.shape}\")\n","    print(f\"Final test shape: {test.shape}\")"]},{"cell_type":"markdown","source":["# **Model Development and Validation**"],"metadata":{"id":"BK-vlEPacGNy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JIStDemTF4ob"},"outputs":[],"source":["with mlflow.start_run(run_name=\"Prophet_Model_Development\"):\n","    print(\"\\nStarting Prophet Model Development...\")\n","\n","\n","    SAMPLE_STORE = 4\n","    SAMPLE_DEPT = 14\n","\n","    mlflow.log_param(\"sample_store\", SAMPLE_STORE)\n","    mlflow.log_param(\"sample_department\", SAMPLE_DEPT)\n","    sample_data = train.loc[(train['Store'] == SAMPLE_STORE) & (train['Dept'] == SAMPLE_DEPT)]\n","    prophet_data = sample_data[['sales', 'Date']].copy()\n","    prophet_data['ds'] = pd.to_datetime(prophet_data['Date'])\n","    prophet_data['y'] = prophet_data['sales']\n","    prophet_data = prophet_data[['ds', 'y']].sort_values('ds')\n","\n","    mlflow.log_param(\"sample_data_points\", len(prophet_data))\n","    mlflow.log_param(\"date_range_sample\", f\"{prophet_data['ds'].min()} to {prophet_data['ds'].max()}\")\n","\n","    print(f\"Sample data shape: {prophet_data.shape}\")\n","    print(f\"Date range: {prophet_data['ds'].min()} to {prophet_data['ds'].max()}\")\n","\n","    #80/20 splitting\n","    split_idx = int(len(prophet_data) * 0.8)\n","    train_prophet = prophet_data[:split_idx].copy()\n","    val_prophet = prophet_data[split_idx:].copy()\n","\n","    mlflow.log_param(\"train_split_ratio\", 0.8)\n","    mlflow.log_param(\"train_points\", len(train_prophet))\n","    mlflow.log_param(\"validation_points\", len(val_prophet))\n","\n","\n","    prophet_params = {\n","        'weekly_seasonality': True,\n","        'daily_seasonality': True,\n","        'yearly_seasonality': 'auto',\n","        'seasonality_mode': 'additive',\n","        'interval_width': 0.95\n","    }\n","\n","    mlflow.log_params(prophet_params)\n","\n","\n","    print(\"Training Prophet model...\")\n","    model = Prophet(**prophet_params)\n","    model.fit(train_prophet)\n","    val_dates = val_prophet[['ds']].copy()\n","    val_forecast = model.predict(val_dates)\n","\n","    #validation stuff\n","    val_rmse = np.sqrt(mse(val_prophet['y'], val_forecast['yhat']))\n","    val_mae = mae(val_prophet['y'], val_forecast['yhat'])\n","\n","    #MAPE (0 ze gayopaze kide tu mokvdeba, mivyvebi mec)\n","    actual_values = val_prophet['y'].values\n","    predicted_values = val_forecast['yhat'].values\n","\n","    # for only non-zero !!!!!!!!!!!!!\n","    non_zero_mask = actual_values != 0\n","    if np.sum(non_zero_mask) > 0:\n","        val_mape = np.mean(np.abs((actual_values[non_zero_mask] - predicted_values[non_zero_mask]) / actual_values[non_zero_mask])) * 100\n","    else:\n","        val_mape = float('inf')\n","\n","\n","    mlflow.log_metric(\"validation_rmse\", val_rmse)\n","    mlflow.log_metric(\"validation_mae\", val_mae)\n","    mlflow.log_metric(\"validation_mape\", val_mape)\n","\n","    print(f\"Validation RMSE: {val_rmse:.2f}\")\n","    print(f\"Validation MAE: {val_mae:.2f}\")\n","    print(f\"Validation MAPE: {val_mape:.2f}%\")"]},{"cell_type":"markdown","source":["# **CV & Hyperparams**"],"metadata":{"id":"IhDNk7D0cLgt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3vmFp_u-F4lk"},"outputs":[],"source":["with mlflow.start_run(run_name=\"Prophet_Cross_Validation\"):\n","    print(\"\\nStarting Cross-Validation and Hyperparameter Tuning...\")\n","\n","    configurations = [\n","        {'weekly_seasonality': True, 'daily_seasonality': False, 'yearly_seasonality': 'auto'},\n","        {'weekly_seasonality': True, 'daily_seasonality': True, 'yearly_seasonality': 'auto'},\n","        {'weekly_seasonality': 15, 'daily_seasonality': False, 'yearly_seasonality': 'auto'},\n","        {'weekly_seasonality': True, 'daily_seasonality': True, 'yearly_seasonality': 15}\n","    ]\n","\n","    best_rmse = float('inf')\n","    best_config = None\n","    cv_results = []\n","\n","    for i, config in enumerate(configurations):\n","        print(f\"Testing configuration {i+1}/{len(configurations)}: {config}\")\n","\n","        with mlflow.start_run(run_name=f\"Prophet_Config_{i+1}\", nested=True):\n","            mlflow.log_params(config)\n","\n","            model_cv = Prophet(**config)\n","            model_cv.fit(train_prophet)\n","            forecast_cv = model_cv.predict(val_dates)\n","\n","\n","            rmse_cv = np.sqrt(mse(val_prophet['y'], forecast_cv['yhat']))\n","            mae_cv = mae(val_prophet['y'], forecast_cv['yhat'])\n","\n","            mlflow.log_metric(\"cv_rmse\", rmse_cv)\n","            mlflow.log_metric(\"cv_mae\", mae_cv)\n","\n","            cv_results.append({\n","                'config': config,\n","                'rmse': rmse_cv,\n","                'mae': mae_cv\n","            })\n","\n","            if rmse_cv < best_rmse:\n","                best_rmse = rmse_cv\n","                best_config = config\n","\n","            print(f\"  RMSE: {rmse_cv:.2f}, MAE: {mae_cv:.2f}\")\n","\n","    # SAUKETESO CONFIG LOGGING\n","    mlflow.log_params({\"best_\" + k: v for k, v in best_config.items()})\n","    mlflow.log_metric(\"best_cv_rmse\", best_rmse)\n","\n","    print(f\"\\nBest configuration: {best_config}\")\n","    print(f\"Best RMSE: {best_rmse:.2f}\")"]},{"cell_type":"markdown","source":["# **Training and full Pipeline**"],"metadata":{"id":"wLTMDYGccSuF"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Oqk-FJr-F4iw"},"outputs":[],"source":["\n","print(\"\\n\" + \"=\"*60)\n","print(\" FULL PROPHET TRAINING - ALL STORE-DEPARTMENT COMBINATIONS\")\n","print(\"=\"*60)\n","\n","with mlflow.start_run(run_name=\"Prophet_Full_Real_Training\"):\n","    print(\"Starting Full Prophet Training for ALL store-department combinations...\")\n","\n","\n","    all_stores = sorted(train['Store'].unique())\n","    all_depts = sorted(train['Dept'].unique())\n","    total_combinations = len(all_stores) * len(all_depts)\n","\n","    print(f\"Training scope: {len(all_stores)} stores × {len(all_depts)} departments\")\n","    print(f\"Total models to train: {total_combinations}\")\n","    print(\"This will train Prophet models for ALL store-department combinations\")\n","    print(\"=\"*60)\n","\n","    mlflow.log_param(\"training_mode\", \"FULL\")\n","    mlflow.log_param(\"num_stores\", len(all_stores))\n","    mlflow.log_param(\"num_departments\", len(all_depts))\n","    mlflow.log_param(\"total_models\", total_combinations)\n","    mlflow.log_param(\"prophet_config\", best_config)\n","\n","\n","\n","    # P i p e l i n e\n","    class RealProphetPipeline:\n","        def __init__(self, prophet_params):\n","            self.prophet_params = prophet_params\n","            self.models = {}\n","            self.training_stats = {\n","                'models_trained': 0,\n","                'models_failed': 0,\n","                'total_training_time': 0,\n","                'failed_combinations': []\n","            }\n","\n","        def fit(self, train_data, stores_to_train, depts_to_train):\n","\n","            import time\n","\n","            total_combinations = len(stores_to_train) * len(depts_to_train)\n","            start_time = time.time()\n","\n","            print(f\" Training {total_combinations} Prophet models...\")\n","\n","            for i, store in enumerate(stores_to_train):\n","                store_start_time = time.time()\n","                store_models_trained = 0\n","                store_models_failed = 0\n","\n","                for j, dept in enumerate(depts_to_train):\n","                    model_start_time = time.time()\n","\n","                    try:\n","                       # store-department combo\n","                        mask = (train_data['Store'] == store) & (train_data['Dept'] == dept)\n","                        data = train_data.loc[mask, ['sales', 'Date']].copy()\n","\n","                        #if we have enough data points\n","                        if len(data) < 10:\n","                            print(f\"XXXXXXX  Skipping Store {store}, Dept {dept}: insufficient data ({len(data)} points)\")\n","                            self.training_stats['failed_combinations'].append((store, dept, \"insufficient_data\"))\n","                            self.training_stats['models_failed'] += 1\n","                            continue\n","\n","                        #data format\n","                        prophet_df = pd.DataFrame({\n","                            'ds': pd.to_datetime(data['Date']),\n","                            'y': data['sales']\n","                        }).sort_values('ds').reset_index(drop=True)\n","\n","                        # Remove any duplicate dates (Prophet requirement)\n","                        prophet_df = prophet_df.drop_duplicates('ds').reset_index(drop=True)\n","\n","                        #training\n","                        model = Prophet(**self.prophet_params)\n","\n","                        #decrease verbose output\n","                        import logging\n","                        logging.getLogger('prophet').setLevel(logging.WARNING)\n","\n","                        model.fit(prophet_df)\n","\n","\n","                        self.models[(store, dept)] = {\n","                            'model': model,\n","                            'training_data_points': len(prophet_df),\n","                            'date_range': (prophet_df['ds'].min(), prophet_df['ds'].max())\n","                        }\n","\n","                        self.training_stats['models_trained'] += 1\n","                        store_models_trained += 1\n","\n","                        model_time = time.time() - model_start_time\n","\n","                    except Exception as e:\n","                        print(f\"X Failed Store {store}, Dept {dept}: {str(e)}\")\n","                        self.training_stats['failed_combinations'].append((store, dept, str(e)))\n","                        self.training_stats['models_failed'] += 1\n","                        store_models_failed += 1\n","\n","\n","                store_time = time.time() - store_start_time\n","                elapsed_total = time.time() - start_time\n","                progress = ((i + 1) / len(stores_to_train)) * 100\n","\n","                print(f\" Store {store} complete: {store_models_trained} trained, {store_models_failed} failed\")\n","                print(f\"   Progress: {progress:.1f}% | Store time: {store_time:.1f}s | Total elapsed: {elapsed_total/60:.1f}min\")\n","\n","\n","                if i > 0:\n","                    avg_time_per_store = elapsed_total / (i + 1)\n","                    remaining_stores = len(stores_to_train) - (i + 1)\n","                    eta_minutes = (remaining_stores * avg_time_per_store) / 60\n","                    print(f\"   ETA: {eta_minutes:.1f} minutes remaining\")\n","\n","                print(\"-\" * 50)\n","\n","            self.training_stats['total_training_time'] = time.time() - start_time\n","\n","            print(f\"\\n TRAINING COMPLETE!\")\n","            print(f\" Models trained: {self.training_stats['models_trained']}\")\n","            print(f\" Models failed: {self.training_stats['models_failed']}\")\n","            print(f\" Total training time: {self.training_stats['total_training_time']/60:.1f} minutes\")\n","            print(f\" Success rate: {(self.training_stats['models_trained']/total_combinations)*100:.1f}%\")\n","\n","            return self\n","\n","        def predict(self, test_data):\n","\n","            print(\"\\n Generating predictions...\")\n","\n","            predictions = []\n","            prediction_stats = {'used_model': 0, 'used_fallback': 0}\n","\n","            for idx, row in test_data.iterrows():\n","                store, dept, date = row['Store'], row['Dept'], row['Date']\n","\n","                if (store, dept) in self.models:\n","\n","                    model_info = self.models[(store, dept)]\n","                    model = model_info['model']\n","                    future_df = pd.DataFrame({'ds': [pd.to_datetime(date)]})\n","\n","                    try:\n","                        forecast = model.predict(future_df)\n","                        pred = forecast['yhat'].iloc[0]\n","                        prediction_stats['used_model'] += 1\n","                    except Exception as e:\n","                        pred = self._fallback_prediction(store, dept, date, test_data)\n","                        prediction_stats['used_fallback'] += 1\n","                else:\n","                    pred = self._fallback_prediction(store, dept, date, test_data)\n","                    prediction_stats['used_fallback'] += 1\n","                predictions.append(max(0, pred))\n","\n","\n","                if (idx + 1) % 10000 == 0:\n","                    print(f\"   Predicted {idx + 1}/{len(test_data)} samples...\")\n","\n","            print(f\"   Predictions complete!\")\n","            print(f\"   Used trained models: {prediction_stats['used_model']}\")\n","            print(f\"   Used fallback: {prediction_stats['used_fallback']}\")\n","\n","            return np.array(predictions)\n","\n","        def _fallback_prediction(self, store, dept, date, test_data):\n","\n","            store_mask = test_data['Store'] == store\n","            dept_mask = test_data['Dept'] == dept\n","\n","            if store_mask.any():\n","                return 1000.0\n","            elif dept_mask.any():\n","                return 800.0\n","            else:\n","                return 500.0\n","\n","\n","\n","\n","   # ACTUAL TRAINING HAPPENS HERE\n","    pipeline = RealProphetPipeline(best_config)\n","\n","\n","    print(\" Starting real Prophet training...\")\n","    pipeline.fit(train, all_stores, all_depts)\n","\n","\n","    mlflow.log_metric(\"models_trained\", pipeline.training_stats['models_trained'])\n","    mlflow.log_metric(\"models_failed\", pipeline.training_stats['models_failed'])\n","    mlflow.log_metric(\"training_time_minutes\", pipeline.training_stats['total_training_time']/60)\n","    mlflow.log_metric(\"success_rate\", (pipeline.training_stats['models_trained']/total_combinations)*100)\n","\n","   # PREDICTIONS\n","\n","\n","    test_subset = test[['Date', 'Store', 'Dept']].copy()\n","    final_predictions = pipeline.predict(test_subset)\n","\n","    predictions_path = f'{FOLDERNAME}/prophet_real_predictions.npy'\n","    np.save(predictions_path, final_predictions)\n","\n","    mlflow.log_artifact(predictions_path, \"predictions\")\n","\n","    pred_mean = np.mean(final_predictions)\n","    pred_std = np.std(final_predictions)\n","    pred_min = np.min(final_predictions)\n","    pred_max = np.max(final_predictions)\n","\n","    mlflow.log_metric(\"predictions_mean\", pred_mean)\n","    mlflow.log_metric(\"predictions_std\", pred_std)\n","    mlflow.log_metric(\"predictions_min\", pred_min)\n","    mlflow.log_metric(\"predictions_max\", pred_max)\n","    mlflow.log_metric(\"total_predictions\", len(final_predictions))\n","\n","    print(f\"\\n PREDICTION STATISTICS:\")\n","    print(f\"   Mean prediction: ${pred_mean:.2f}\")\n","    print(f\"   Std deviation: ${pred_std:.2f}\")\n","    print(f\"   Min prediction: ${pred_min:.2f}\")\n","    print(f\"   Max prediction: ${pred_max:.2f}\")\n","    print(f\"   Total predictions: {len(final_predictions)}\")\n","\n","    #submission creation\n","\n","\n","    submission = pd.read_csv(DATAPATH + 'sampleSubmission.csv')\n","    submission['Weekly_Sales'] = final_predictions\n","\n","\n","    submission_path = f'{FOLDERNAME}/prophet_real_submission.csv'\n","    submission.to_csv(submission_path, index=False)\n","\n","\n","    mlflow.log_artifact(submission_path, \"submission\")\n","\n","    print(f\"\\n FILES SAVED:\")\n","    print(f\"   Predictions: {predictions_path}\")\n","    print(f\"   Submission: {submission_path}\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\" FULL PROPHET TRAINING COMPLETED SUCCESSFULLY!\")\n","    print(\"=\"*60)\n","    print(f\" Trained models: {pipeline.training_stats['models_trained']} out of {total_combinations}\")\n","    print(f\" Training time: {pipeline.training_stats['total_training_time']/60:.1f} minutes\")\n","    print(f\" Success rate: {(pipeline.training_stats['models_trained']/total_combinations)*100:.1f}%\")\n","    print(f\" Predictions generated: {len(final_predictions)}\")\n","    print(f\" Submission file ready for Kaggle\")\n","    print(\"=\"*60)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyMIZYWnBmUUFY3ncbVHwBZr"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}